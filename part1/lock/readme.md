# 死锁，活锁和锁的饥饿问题
    我将从如下3个方面剖析
    1. 死锁
    2. 活锁
    3. 锁的饥饿问题

# 死锁
    死锁是所有并发进程都在彼此等待的状态。 在这种情况下，如果没有外部干预，程序将永远不会恢复。
    如果这听起来很严峻，那是因为它确实很严峻！ Go运行时会检测到一些死锁（所有的例程必须被阻塞或“休眠”），但这对于帮助你防止死锁产生没有多大帮助

# 出现死锁需满足的条件
    出现僵局时必定存在一些条件，1971年，埃德加科夫曼在一篇论文中列举了这些条件。这些条件现在称为科夫曼条件，是帮助检测，防止和纠正死锁的技术基础。

    科夫曼条件如下：

    相互排斥
    并发进程在任何时候都拥有资源的独占权。

    等待条件
    并发进程必须同时持有资源并等待额外的资源。

    没有抢占
    并发进程持有的资源只能由该进程释放，因此它满足了这种情况。

    循环等待
    并发进程（P1）等待并发进程（P2），同时P2也在等待P1，因此也符合"循环等待"这一条件

# 解决死锁的方法
    科夫曼条件同样有助于我们规避死锁。如果我们确保至少有一个条件不成立，就可以防止发生死锁。不幸的是，实际上这些条件很难推理，因此难以预防。网上大量充斥着被死锁困扰的开发人员的求助，一旦有人指出它就很明显，但通常需要另一双眼睛

# 活锁(livelock.go)
    活锁是正在主动执行并发操作的程序，但这些操作无法向前移动程序的状态。

    你有没有在走廊走向另一个人？ 她移动到一边让你通过，但你也是这样做的。 所以你转移到另一边，但她也是这样做的。 想象这会永远持续下去，这就是活锁

# 死锁和活锁的区别
    在我看来，活锁比死锁更难以发现，因为它看起来好像程序正在工作。 如果活锁程序在你的机器上运行，并且你查看了CPU利用率以确定它是否在执行任何操作，那么你可能会认为它是。 根据活锁的不同，它甚至可能会发出其他信号，使你认为它正在工作。 然而，一直以来，你的程序都扮演着走廊洗牌的永恒游戏。

# 关于并发进程的饥饿问题探讨(锁的饥饿问题)
    饥饿是指并发进程无法获得执行工作所需的任何资源的情况。

# 解决饥饿问题的方法
    检测和解决饥饿的方法之一就是就是记录程序完成的时间，然后确定你的程序执行速度是否与预期的一样高

# 活锁和饥饿的区别
    当我们讨论活锁时，每个goroutine所缺乏的资源就是一个共享锁。 活锁需要与饥饿分开讨论，因为在活锁过程中，所有并发进程都是平等的，并且没有任何任务可以被完成。 更广泛地说，饥饿通常意味着有一个或多个贪婪的并发进程不公平地阻止一个或多个并发进程尽可能有效地完成工作，或者根本不可能完成工作。

    下面这个例子展示了一个贪婪的goroutine和一个知足的goroutine：

    var wg sync.WaitGroup
    var sharedLock sync.Mutex
    const runtime = 1*time.Second
    //贪婪的goroutine
    greedyWorker := func() {
        defer wg.Done()

        var count int
        for begin := time.Now(); time.Since(begin) <= runtime; { 
            sharedLock.Lock()
            //一次性停顿3ns会占用别的goroutine的资源,会出现资源抢夺的情况
            time.Sleep(3*time.Nanosecond) 
            sharedLock.Unlock()
            count++
        }

        fmt.Printf("Greedy worker was able to execute %v work loops\n", count)
    }
    //知足的goroutine按需要执行
    politeWorker := func() {
        defer wg.Done()

        var count int
        for begin := time.Now(); time.Since(begin) <= runtime; {
            //执行共享锁,每次都按需要停顿
            sharedLock.Lock()
            time.Sleep(1*time.Nanosecond) 
            sharedLock.Unlock()

            sharedLock.Lock() 
            time.Sleep(1*time.Nanosecond) 
            sharedLock.Unlock()

            sharedLock.Lock() 
            time.Sleep(1*time.Nanosecond) 
            sharedLock.Unlock()

            count++
        }
        fmt.Printf("Polite worker was able to execute %v work loops.\n", count)
    }

    wg.Add(2)
    go greedyWorker()
    go politeWorker()

    wg.Wait()
    这个代码段会输出：

    Polite worker was able to execute 289777 work loops. Greedy worker was able to execute 471287 work loops
    greedy 贪婪地持有整个工作循环的共享锁，而polite 试图只在需要时才锁定。 二者都进行了相同数量的模拟工作（休眠时间为三纳秒），但正如你在相同的时间内看到的那样，greedy 几乎完成了两倍的工作量！

    但在这里我们要清楚的了解到，greedy不必要的扩大了对共享锁的控制，并且(通过饥饿)阻碍了polite有效的执行。

    我们在例子中使用计数的方式识别饥饿，在记录和抽样度量指标时这是一个很不错的方法。检测和解决饥饿的方法之一就是就是记录程序完成的时间，然后确定你的程序执行速度是否与预期的一样高。

    值得一提的是，前面的代码示例也可以作为进行同步内存访问的性能分支示例。 因为同步访问内存的代价很高，所以扩大我们的锁定范围可能会产生额外的代价。 另一方面，正如我们所看到的那样，我们冒着令其他并发进程挨饿的风险。
    如果你利用内存访问同步，你必须在性能粗粒度同步和公平性细粒度同步之间找到平衡点。 当开始调试应用程序时，我强烈建议你将内存访问同步仅限于程序的关键部分; 如果同步成为性能问题，则可以扩大范围。 除此之外，其他的解决方式可能会更难以操作。

    因此，饥饿可能会导致程序无效或不正确。 前面的例子表明了执行效率是如何被降低的，如果你有一个非常贪婪的并发进程，以至于完全阻止另一个并发进程完成工作，那么你的问题就大了。

    我们还需要考虑来自程序之外导致的饥饿问题。请记住，饥饿还可以产生于于CPU，内存，文件句柄和数据库连接：任何必须共享的资源都是饥饿的候选对象。






